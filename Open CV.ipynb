{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Resources/lena.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"output\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vid = cv2.VideoCapture(\"Resources/test_video.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VideoCapture 0000022A96908990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-r2ue8w6k\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6b8eed00f45b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"video\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0XFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-r2ue8w6k\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    success, image = vid.read()\n",
    "    cv2.imshow(\"video\",image)\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "webcam = cv2.VideoCapture(0)\n",
    "webcam.set(3,640) # width\n",
    "webcam.set(4,480) # height\n",
    "#webcam.set(10,100) # brightness\n",
    "\n",
    "while True:\n",
    "    success, image = webcam.read()\n",
    "    cv2.imshow(\"video\",image)\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # grayscale image\n",
    "cv2.imshow(\"gray_image\", imgGray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgBlur = cv2.GaussianBlur(imgGray, (11,11),0) # blur image\n",
    "cv2.imshow(\"blur_image\", imgBlur)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgCanny = cv2.Canny(img, 100,200) # shows edges.. \n",
    "cv2.imshow(\"cany_image\", imgCanny)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "imgDialation = cv2.dilate(imgCanny, kernel, iterations = 1) # make thick edges.. \n",
    "cv2.imshow(\"dilate_image\", imgDialation)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgEroded = cv2.erode(imgDialation, kernel, iterations =2) # make thin edges.. \n",
    "cv2.imshow(\"erode_image\", imgEroded)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize and Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"Resources/lambo.png\")\n",
    "cv2.imshow(\"output\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape  # (height, width, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgResized = cv2.resize(img, (300,200)) # resize param: width = 300, height = 200\n",
    "\n",
    "cv2.imshow(\"output\", imgResized)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(imgResized.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgCrop = img[0:200, 200:500]\n",
    "\n",
    "cv2.imshow(\"output\", imgCrop)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(imgCrop.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes & texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "\n",
    "cv2.imshow(\"output\", img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(img.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[200:300, 300:500] = 255,255,0 # assigning colors to a diff section..\n",
    "\n",
    "cv2.imshow(\"output\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.line(img, (0,0), (img.shape[1], img.shape[0]), (255,12,100),3) ## draws line\n",
    "\n",
    "cv2.imshow(\"output\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  we can use rectangle, circle and many more see doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(img, \"GHORAR DIM\", (300,100), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,255), 1) # put texts\n",
    "\n",
    "cv2.imshow(\"output\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"Resources/cards.jpg\")\n",
    "cv2.imshow(\"output\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 250, 350\n",
    "\n",
    "pst1 = np.float32([[111,219],[287,188],[154,482],[352,440]]) # points that we want to show\n",
    "pst2 = np.float32([[0,0],[width,0],[0,height],[width,height]]) # points where we want to set the points of pst1\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(pst1,pst2)\n",
    "\n",
    "imgOut = cv2.warpPerspective(img, matrix, (width,height))\n",
    "\n",
    "cv2.imshow(\"output\", imgOut)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgHor = np.hstack((img,img)) # both of the img has to have same no of channels\n",
    "\n",
    "cv2.imshow(\"output\", imgHor)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgVer = np.vstack((img,img)) # both of the img has to have same no of channels\n",
    "\n",
    "cv2.imshow(\"output\", imgVer)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"output\", imgHSV)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### method for stacking diff images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"Resources/lambo.png\")\n",
    "img = cv2.resize(img, (300,200)) # resize param: width = 300, height = 200\n",
    "\n",
    "#for creating the trackbar\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "# create a trackbar\n",
    "cv2.namedWindow(\"TrackBars\")\n",
    "cv2.resizeWindow(\"TrackBars\", 640, 240)\n",
    "cv2.createTrackbar(\"Hue min\", \"TrackBars\", 0, 179, empty)\n",
    "cv2.createTrackbar(\"Hue max\", \"TrackBars\", 19, 179, empty)\n",
    "cv2.createTrackbar(\"Sat min\", \"TrackBars\", 110, 255, empty)\n",
    "cv2.createTrackbar(\"Sat max\", \"TrackBars\", 240, 255, empty)\n",
    "cv2.createTrackbar(\"Val min\", \"TrackBars\", 153, 255, empty)\n",
    "cv2.createTrackbar(\"Val max\", \"TrackBars\", 255, 255, empty)\n",
    "\n",
    "# get values from the trackbar\n",
    "while True:\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    imgHSV = cv2.resize(imgHSV, (300,200)) # resize param: width = 300, height = 200\n",
    "    h_min = cv2.getTrackbarPos(\"Hue min\",\"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue max\",\"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat min\",\"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat max\",\"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val min\",\"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val max\",\"TrackBars\")\n",
    "    # create a mask\n",
    "    lower = np.array([h_min, s_min, v_min])\n",
    "    upper = np.array([h_max, s_max, v_max])\n",
    "    mask = cv2.inRange(imgHSV, lower, upper)\n",
    "    finalImage = cv2.bitwise_and(img, img, mask = mask)\n",
    "    \n",
    "    #show all images seperately.. \n",
    "    \n",
    "    \"\"\"\n",
    "    cv2.imshow(\"hsv img\", imgHSV)\n",
    "    cv2.imshow(\"main img\", img)\n",
    "    cv2.imshow(\"mask img\", mask)  \n",
    "    cv2.imshow(\"final img\", finalImage)\n",
    "    \"\"\" \n",
    "    #show all images stacked on a single window.. \n",
    "   \n",
    "    imgStack = stackImages(0.6, ([img, imgHSV],[mask, finalImage]))\n",
    "    cv2.imshow(\"final stacked img\", imgStack)\n",
    "\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContours(img):\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        #print(area)\n",
    "        if area>500:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            #print(peri)\n",
    "            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "            #print(len(approx))\n",
    "            objCor = len(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "\n",
    "            if objCor ==3: objectType =\"Tri\"\n",
    "            elif objCor == 4:\n",
    "                aspRatio = w/float(h)\n",
    "                if aspRatio >0.98 and aspRatio <1.03: objectType= \"Square\"\n",
    "                else:objectType=\"Rectangle\"\n",
    "            elif objCor>4: objectType= \"Circles\"\n",
    "            else:objectType=\"None\"\n",
    "\n",
    "\n",
    "\n",
    "            cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(imgContour,objectType,\n",
    "                        (x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.7,\n",
    "                        (0,0,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('Resources/shapes.png')\n",
    "imgContour = img.copy()\n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray,(7,7),1)\n",
    "imgCanny = cv2.Canny(imgBlur,50,50)\n",
    "imgBlank = np.zeros_like(img)\n",
    "getContours(imgCanny)\n",
    "\n",
    "\n",
    "imgStack = stackImages(0.5,([img,imgGray,imgBlur],\n",
    "                            [imgCanny,imgContour, imgBlank]))\n",
    "                            \n",
    "\n",
    "cv2.imshow(\"Stack\", imgStack)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "faceCascade= cv2.CascadeClassifier(\"Resources/haarcascade_frontalface_default.xml\")\n",
    "img = cv2.imread('Resources/lena.png')\n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = faceCascade.detectMultiScale(imgGray,1.1,4)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Result\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "faceCascade= cv2.CascadeClassifier(\"Resources/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "cap.set(10,150)\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale(imgGray)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),8)\n",
    "    \n",
    "    cv2.imshow(\"Result\", img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual Paint Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting for webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "cap.set(10,150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContours(img):\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    x,y,w,h = 0,0,0,0\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area>500:\n",
    "            #cv2.drawContours(imgResult, cnt, -1, (255, 0, 0), 3)\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "    return x+w//2,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Find Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findColor(img,myColors,myColorValues):\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    count = 0\n",
    "    newPoints=[]\n",
    "    for color in myColors:\n",
    "        lower = np.array(color[0:3])\n",
    "        upper = np.array(color[3:6])\n",
    "        mask = cv2.inRange(imgHSV,lower,upper)\n",
    "        x,y=getContours(mask)\n",
    "        cv2.circle(imgResult,(x,y),15,myColorValues[count],cv2.FILLED)\n",
    "        if x!=0 and y!=0:\n",
    "            newPoints.append([x,y,count])\n",
    "        count +=1\n",
    "        #cv2.imshow(str(color[0]),mask)\n",
    "    return newPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Draw on canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawOnCanvas(myPoints,myColorValues):\n",
    "    for point in myPoints:\n",
    "        cv2.circle(imgResult, (point[0], point[1]), 10, myColorValues[point[2]], cv2.FILLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myColors = [[5,107,0,19,255,255],\n",
    "          [133,56,0,159,156,255],\n",
    "          [57,76,0,100,255,255],\n",
    "          [90,48,0,118,255,255]]\n",
    "myColorValues = [[51,153,255],          ## BGR\n",
    "                [255,0,255],\n",
    "                [0,255,0],\n",
    "               [255,0,0]]\n",
    "#myColors = [[0,0,0,180,255,40]\n",
    "          #  ]\n",
    "#myColorValues = [[0,0,0]      ## BGR\n",
    "        #         ]\n",
    "myPoints =  []  ## [x , y , colorId ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  main method to run t he cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgResult = img.copy()\n",
    "    newPoints = findColor(img, myColors,myColorValues)\n",
    "    if len(newPoints)!=0:\n",
    "        for newP in newPoints:\n",
    "            myPoints.append(newP)\n",
    "    if len(myPoints)!=0:\n",
    "        drawOnCanvas(myPoints,myColorValues)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Result\", imgResult)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To Find the desired mask vale from web cam (Only for debug purpose)..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "cap.set(10,150)\n",
    "\n",
    "#for creating the trackbar\n",
    "def empty(a):\n",
    "    pass\n",
    "    \n",
    "# create a trackbar\n",
    "cv2.namedWindow(\"TrackBars\")\n",
    "cv2.resizeWindow(\"TrackBars\", 640, 240)\n",
    "cv2.createTrackbar(\"Hue min\", \"TrackBars\", 0, 180, empty)\n",
    "cv2.createTrackbar(\"Hue max\", \"TrackBars\", 180, 180, empty)\n",
    "cv2.createTrackbar(\"Sat min\", \"TrackBars\", 0, 255, empty)\n",
    "cv2.createTrackbar(\"Sat max\", \"TrackBars\", 255, 255, empty)\n",
    "cv2.createTrackbar(\"Val min\", \"TrackBars\", 0, 255, empty)\n",
    "cv2.createTrackbar(\"Val max\", \"TrackBars\", 40, 255, empty)\n",
    "    \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h_min = cv2.getTrackbarPos(\"Hue min\",\"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue max\",\"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat min\",\"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat max\",\"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val min\",\"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val max\",\"TrackBars\")\n",
    "    # create a mask\n",
    "    lower = np.array([h_min, s_min, v_min])\n",
    "    upper = np.array([h_max, s_max, v_max])\n",
    "    mask = cv2.inRange(imgHSV, lower, upper)\n",
    "    finalImage = cv2.bitwise_and(img, img, mask = mask)\n",
    "    cv2.imshow(\"final img\", finalImage)\n",
    "    \n",
    "    cv2.imshow(\"Result\", img)\n",
    "    \n",
    "\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Scan Project.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### preprocess the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img):\n",
    "    imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    imgBlur = cv2.GaussianBlur(imgGray,(5,5),1)\n",
    "    imgCanny = cv2.Canny(imgBlur,200,200)\n",
    "    kernel = np.ones((5,5))\n",
    "    imgDial = cv2.dilate(imgCanny,kernel,iterations=2)\n",
    "    imgThres = cv2.erode(imgDial,kernel,iterations=1)\n",
    "    return imgThres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### get the Contours.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContours(img):\n",
    "    biggest = np.array([])\n",
    "    maxArea = 0\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area>5000:\n",
    "            #cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "            if area >maxArea and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                maxArea = area\n",
    "    cv2.drawContours(imgContour, biggest, -1, (255, 0, 0), 20)\n",
    "    return biggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### reorder the image (for point misplacing..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder (myPoints):\n",
    "    myPoints = myPoints.reshape((4,2))\n",
    "    myPointsNew = np.zeros((4,1,2),np.int32)\n",
    "    add = myPoints.sum(1)\n",
    "    #print(\"add\", add)\n",
    "    myPointsNew[0] = myPoints[np.argmin(add)]\n",
    "    myPointsNew[3] = myPoints[np.argmax(add)]\n",
    "    diff = np.diff(myPoints,axis=1)\n",
    "    myPointsNew[1]= myPoints[np.argmin(diff)]\n",
    "    myPointsNew[2] = myPoints[np.argmax(diff)]\n",
    "    #print(\"NewPoints\",myPointsNew)\n",
    "    return myPointsNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### wrap the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWarp(img,biggest):\n",
    "    biggest = reorder(biggest)\n",
    "    pts1 = np.float32(biggest)\n",
    "    pts2 = np.float32([[0, 0], [widthImg, 0], [0, heightImg], [widthImg, heightImg]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    imgOutput = cv2.warpPerspective(img, matrix, (widthImg, heightImg))\n",
    "\n",
    "    imgCropped = imgOutput[20:imgOutput.shape[0]-20,20:imgOutput.shape[1]-20]\n",
    "    imgCropped = cv2.resize(imgCropped,(widthImg,heightImg))\n",
    "\n",
    "    return imgCropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### stack images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### main func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################################\n",
    "widthImg=540\n",
    "heightImg =640\n",
    "#####################################\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(10,150)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.resize(img,(widthImg,heightImg))\n",
    "    imgContour = img.copy()\n",
    "\n",
    "    imgThres = preProcessing(img)\n",
    "    biggest = getContours(imgThres)\n",
    "    \n",
    "    if biggest.size !=0:\n",
    "        imgWarped=getWarp(img,biggest)\n",
    "        # imageArray = ([img,imgThres],\n",
    "        #           [imgContour,imgWarped])\n",
    "        imageArray = ([imgContour, imgWarped])\n",
    "        cv2.imshow(\"ImageWarped\", imgWarped)\n",
    "    else:\n",
    "        # imageArray = ([img, imgThres],\n",
    "        #               [img, img])\n",
    "        imageArray = ([imgContour, img])\n",
    "\n",
    "    stackedImages = stackImages(0.6,imageArray)\n",
    "    cv2.imshow(\"WorkFlow\", stackedImages)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number plate detection - project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#############################################\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "nPlateCascade = cv2.CascadeClassifier(\"Resources/haarcascade_russian_plate_number.xml\")\n",
    "minArea = 200\n",
    "color = (255,0,255)\n",
    "###############################################\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "cap.set(10,150)\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    numberPlates = nPlateCascade.detectMultiScale(imgGray, 1.1, 10)\n",
    "    for (x, y, w, h) in numberPlates:\n",
    "        area = w*h\n",
    "        if area >minArea:\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 2)\n",
    "            cv2.putText(img,\"Number Plate\",(x,y-5),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX_SMALL,1,color,2)\n",
    "            imgRoi = img[y:y+h,x:x+w]\n",
    "            cv2.imshow(\"ROI\", imgRoi)\n",
    "\n",
    "    cv2.imshow(\"Result\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        cv2.imwrite(\"Resources/Scanned/NoPlate_\"+str(count)+\".jpg\",imgRoi)\n",
    "        cv2.rectangle(img,(0,200),(640,300),(0,255,0),cv2.FILLED)\n",
    "        cv2.putText(img,\"Scan Saved\",(150,265),cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    2,(0,0,255),2)\n",
    "        cv2.imshow(\"Result\",img)\n",
    "        cv2.waitKey(500)\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
